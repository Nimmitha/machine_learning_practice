{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . .\n",
      ". . .\n",
      ". . .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class TicTacToe:\n",
    "    def __init__(self):\n",
    "        self.board = np.zeros((3, 3), dtype=int)  # 0 = empty, 1 = player, -1 = AI\n",
    "\n",
    "    def reset(self):\n",
    "        self.board = np.zeros((3, 3), dtype=int)\n",
    "\n",
    "    def make_move(self, row, col, player):\n",
    "        if self.board[row, col] == 0:\n",
    "            self.board[row, col] = player\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def check_winner(self):\n",
    "        # Check rows, columns, and diagonals for a winner\n",
    "        for i in range(3):\n",
    "            if abs(sum(self.board[i, :])) == 3 or abs(sum(self.board[:, i])) == 3:\n",
    "                return np.sign(sum(self.board[i, :]))  # Winner is player or AI\n",
    "        if abs(self.board.trace()) == 3 or abs(np.fliplr(self.board).trace()) == 3:\n",
    "            return np.sign(self.board.trace())\n",
    "        if not (self.board == 0).any():  # Draw if board is full\n",
    "            return 0\n",
    "        return None  # Game is still ongoing\n",
    "\n",
    "    def print_board(self):\n",
    "        for row in self.board:\n",
    "            print(\" \".join([str(cell) if cell != 0 else \".\" for cell in row]))\n",
    "        print()\n",
    "\n",
    "# Initialize and display the game board\n",
    "game = TicTacToe()\n",
    "game.print_board()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-10 20:45:50.495071: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-10 20:45:50.727969: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-10 20:45:54.444020: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-10 20:45:54.595821: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-10 20:45:54.595868: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-10 20:45:54.596983: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-10 20:45:54.600915: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-10 20:45:54.601103: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-10 20:45:54.601184: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-10 20:45:55.176900: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-10 20:45:55.176965: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-10 20:45:55.176974: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-11-10 20:45:55.176996: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-10 20:45:55.177046: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1756 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               1280      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 9)                 297       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,913\n",
      "Trainable params: 11,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim=9, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(9, activation='linear'))\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_data():\n",
    "    data = []\n",
    "    for _ in range(1000):  # Generate a dataset of 1000 games\n",
    "        game = TicTacToe()\n",
    "        states = []\n",
    "        moves = []\n",
    "        while True:\n",
    "            current_state = game.board.flatten()\n",
    "            available_moves = list(zip(*np.where(game.board == 0)))\n",
    "            if not available_moves:\n",
    "                break\n",
    "            move = available_moves[np.random.choice(len(available_moves))]\n",
    "            states.append(current_state)\n",
    "            moves.append(move)\n",
    "            game.make_move(*move, 1 if len(states) % 2 == 1 else -1)  # Alternate between player and AI\n",
    "            if game.check_winner() is not None:\n",
    "                break\n",
    "        data.append((states, moves, game.check_winner()))\n",
    "    return data\n",
    "\n",
    "training_data = generate_training_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " 24/240 [==>...........................] - ETA: 0s - loss: 0.1138 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-10 20:46:41.044410: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 2s 5ms/step - loss: 0.1115\n",
      "Epoch 2/50\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 0.1105\n",
      "Epoch 3/50\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 0.1101\n",
      "Epoch 4/50\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 0.1096\n",
      "Epoch 5/50\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 0.1092\n",
      "Epoch 6/50\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 0.1087\n",
      "Epoch 7/50\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 0.1083\n",
      "Epoch 8/50\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 0.1078\n",
      "Epoch 9/50\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 0.1074\n",
      "Epoch 10/50\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 0.1069\n",
      "Epoch 11/50\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 0.1065\n",
      "Epoch 12/50\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 0.1061\n",
      "Epoch 13/50\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 0.1055\n",
      "Epoch 14/50\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 0.1052\n",
      "Epoch 15/50\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 0.1048\n",
      "Epoch 16/50\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 0.1044\n",
      "Epoch 17/50\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 0.1042\n",
      "Epoch 18/50\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 0.1037\n",
      "Epoch 19/50\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 0.1035\n",
      "Epoch 20/50\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 0.1032\n",
      "Epoch 21/50\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 0.1028\n",
      "Epoch 22/50\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 0.1026\n",
      "Epoch 23/50\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 0.1022\n",
      "Epoch 24/50\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 0.1019\n",
      "Epoch 25/50\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 0.1018\n",
      "Epoch 26/50\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.1015\n",
      "Epoch 27/50\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 0.1011\n",
      "Epoch 28/50\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.1009\n",
      "Epoch 29/50\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 0.1007\n",
      "Epoch 30/50\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 0.1003\n",
      "Epoch 31/50\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.1003\n",
      "Epoch 32/50\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.1000\n",
      "Epoch 33/50\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.0998\n",
      "Epoch 34/50\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.0996\n",
      "Epoch 35/50\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 0.0994\n",
      "Epoch 36/50\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 0.0992\n",
      "Epoch 37/50\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 0.0990\n",
      "Epoch 38/50\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.0989\n",
      "Epoch 39/50\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.0987\n",
      "Epoch 40/50\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.0986\n",
      "Epoch 41/50\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.0983\n",
      "Epoch 42/50\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.0983\n",
      "Epoch 43/50\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.0980\n",
      "Epoch 44/50\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.0980\n",
      "Epoch 45/50\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.0978\n",
      "Epoch 46/50\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 0.0977\n",
      "Epoch 47/50\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.0976\n",
      "Epoch 48/50\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 0.0974\n",
      "Epoch 49/50\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 0.0973\n",
      "Epoch 50/50\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 0.0973\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff4748b2eb0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_data(training_data):\n",
    "    X, y = [], []\n",
    "    for states, moves, result in training_data:\n",
    "        for i in range(len(states)):\n",
    "            X.append(states[i])\n",
    "            target = np.zeros(9)\n",
    "            move = moves[i][0] * 3 + moves[i][1]\n",
    "            target[move] = 1 if result == 1 else -1  # Reward win moves, penalize loss moves\n",
    "            y.append(target)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X, y = preprocess_data(training_data)\n",
    "model.fit(X, y, epochs=50, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . .\n",
      ". . .\n",
      ". . .\n",
      "\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      ". 1 .\n",
      ". . .\n",
      ". -1 .\n",
      "\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      ". 1 1\n",
      ". . .\n",
      ". -1 -1\n",
      "\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      ". 1 1\n",
      ". -1 .\n",
      "1 -1 -1\n",
      "\n",
      "You won!\n"
     ]
    }
   ],
   "source": [
    "def model_move(game, model):\n",
    "    state = game.board.flatten().reshape(1, -1)\n",
    "    predictions = model.predict(state)[0]\n",
    "    for i in np.argsort(predictions)[::-1]:\n",
    "        row, col = divmod(i, 3)\n",
    "        if game.board[row, col] == 0:\n",
    "            return (row, col)\n",
    "    return None  # No valid moves\n",
    "\n",
    "# Play a game against the AI\n",
    "game = TicTacToe()\n",
    "while True:\n",
    "    game.print_board()\n",
    "    row, col = map(int, input(\"Enter your move (row col): \").split())\n",
    "    game.make_move(row, col, 1)\n",
    "    if game.check_winner() is not None:\n",
    "        break\n",
    "\n",
    "    ai_move = model_move(game, model)\n",
    "    game.make_move(ai_move[0], ai_move[1], -1)\n",
    "    if game.check_winner() is not None:\n",
    "        break\n",
    "\n",
    "winner = game.check_winner()\n",
    "if winner == 1:\n",
    "    print(\"You won!\")\n",
    "elif winner == -1:\n",
    "    print(\"AI won!\")\n",
    "else:\n",
    "    print(\"It's a draw!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlgeneral",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
